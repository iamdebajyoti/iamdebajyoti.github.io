{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from pandas.io.formats.style import Styler\n",
    "\n",
    "##### STEP 0 #####\n",
    "\n",
    "### setting file paths\n",
    "\n",
    "print(\"Please enter the following inputs Filenames with the full path ...\")\n",
    "\n",
    "# order_file = input(r'FILE  _Order_Tracking_Report-_DXC_-Queensland_Rail :: ')\n",
    "order_file = r\"C:\\DEB\\DXC_Automation\\UCMS_31107\\279577_Order_Tracking_Report-_DXC_-Queensland_Rail.xls\"\n",
    "# dashboard_file = input(r'FILE  Daily dashboard :: ')\n",
    "dashboard_file = r\"C:\\DEB\\DXC_Automation\\UCMS_31107\\Daily dashboard.xlsx\"\n",
    "# lease_supl_cons_file = input(r'FILE  DXC Lease Supplements Consolidated :: ')\n",
    "lease_supl_cons_file = r\"C:\\DEB\\DXC_Automation\\UCMS_31107\\DXC Lease Supplements Consolidated.xls\"\n",
    "# monthly_rental_file = input(r'FILE  Monthly rental prize :: ')\n",
    "monthly_rental_file = r\"C:\\DEB\\DXC_Automation\\UCMS_31107\\Monthly rental prize.xlsx\"\n",
    "#output_file = \n",
    "\n",
    "### setting up the log file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Output_File = pd.DataFrame(columns=[\"Country\",\"Customer\",\"Contract Vendor\",\"Contract Term\",\"Billing Cycle\",\"Contract Equipment Cost IBU\",\"Contract Lease Payment\",\"Order Number\",\"Serial Number\",\"Need Asset Tag RE\",\"Repository State\",\"Repository Sub State\",\"Installation Date\",\"Need PO RE\",\"Asset Description\",\"PO Number\",\"Order Qty\",\"Order Qty Reconciled\",\"Net Price\",\"Rental per Asset\",\"Reconcilied\"], index=None)\n",
    "df_Output_File.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##### STEP 1 #####\n",
    "In this step Order Tracking file data would be processed - Serial Numbers would be splitted to multiple rows and then 2 filters are applied based on Product Description and Brand Description.\n",
    "The resulting dataframe would be used as the referrence DF for the final Output File\n",
    "''' \n",
    "# os.path.join()\n",
    "df_orders = pd.read_excel(order_file, sheet_name=\"Order Status Data\", header=0, usecols=[\"Po Num\", \"Order Num\", \"Product Desc\", \"Brand Desc\", \"Combine svc tag\", \"Order Qty\"], encoding=\"ISO-8859-1\", index_col=None, engine=None, na_values=None)\n",
    "df_orders[\"Order Qty Reconciled\"] = []\n",
    "\n",
    "row_start = 0\n",
    "row_end = df_orders.shape[0]    \n",
    "total_po_nums = total_order_numbers = total_serial_numbers = 0\n",
    "po_nums_missing = order_nums_missing = serial_numbers_missing = 0\n",
    "\n",
    "df_new_rows = pd.DataFrame(columns=[\"Po Num\", \"Order Num\", \"Product Desc\", \"Brand Desc\", \"Combine svc tag\", 'Order Qty', 'Order Qty Reconciled'])\n",
    "for each_row in range(row_start,row_end):\n",
    "    po_num = df_orders.iloc[each_row,0]\n",
    "    order_num = df_orders.iloc[each_row,1]\n",
    "    serial_numbers = df_orders.iloc[each_row,4]\n",
    "    # print(len(df_orders.iloc[66,4].split(sep=\",\")))\n",
    "    if (isinstance(po_num, np.int64)):\n",
    "        total_po_nums += 1\n",
    "    else:\n",
    "        po_nums_missing += 1\n",
    "        \n",
    "    if (isinstance(order_num, np.int64)):\n",
    "        total_order_numbers += 1\n",
    "    else:\n",
    "        order_nums_missing +=1\n",
    "    \n",
    "    if (isinstance(serial_numbers, str)):\n",
    "        serial_numbers_count = len(serial_numbers.split(sep=\",\"))\n",
    "        total_serial_numbers = total_serial_numbers + serial_numbers_count\n",
    "        if serial_numbers_count >1:\n",
    "            if serial_numbers_count != df_orders.iloc[each_row,5]:\n",
    "                df_orders.iloc[each_row,6] = \"ORDER-SUPPLY MISMATCH for this PO\"\n",
    "            else:\n",
    "                df_orders.iloc[each_row,6] = \"Supply as per Order\"\n",
    "\n",
    "            serial_numbers_list = serial_numbers.split(sep=\",\") ## convert the serial number chunks to a list\n",
    "            ## replace the cell with the first serial number\n",
    "            serial_num_first_one = tuple(serial_numbers_list)[0]\n",
    "            df_orders.iloc[each_row,4] = serial_num_first_one\n",
    "            ## now the other serial numbers\n",
    "            serial_num_next_ones = tuple(serial_numbers_list)[1:]\n",
    "#             print(serial_num_first_one)\n",
    "#             print(serial_num_next_ones)\n",
    "#             print(\"=\"*20)\n",
    "            ## preparing the list of values for the new row\n",
    "            cnt = 0\n",
    "            for next_serials in range(0, len(serial_num_next_ones)):\n",
    "                new_list = list()\n",
    "                new_list.append(df_orders.iloc[each_row,0])\n",
    "                new_list.append(df_orders.iloc[each_row,1])\n",
    "                new_list.append(df_orders.iloc[each_row,2])\n",
    "                new_list.append(df_orders.iloc[each_row,3])\n",
    "                new_list.append(serial_num_next_ones[next_serials])                            \n",
    "                new_list.append(df_orders.iloc[each_row,5])\n",
    "                cnt += 1\n",
    "#                 print(next_serials, serial_num_next_ones[next_serials])\n",
    "            \n",
    "            ## converting the list to a Series\n",
    "                temp_series = pd.Series(new_list, name=\"MoreSerials\", index = df_orders.columns)\n",
    "                df_new_rows = df_new_rows.append(temp_series, ignore_index=True)\n",
    "                \n",
    "#         print(\"{} added\".format(cnt))\n",
    "\n",
    "    else:       \n",
    "        serial_numbers_missing +=1\n",
    "        \n",
    "'''    \n",
    "print(\"Order Tracking Report before unpacking has - {} - rows\".format(df_orders.shape[0]))\n",
    "print(\"Total number of Po numbers found - {}\".format(total_po_nums))\n",
    "print(\"Total number of Po numbers missing - {}\".format(po_nums_missing))\n",
    "print(\"Total number of Order numbers found - {}\".format(total_order_numbers))\n",
    "print(\"Total number of Order numbers missing - {}\".format(order_nums_missing))\n",
    "print(\"Total number of serial numbers found - {}\".format(total_serial_numbers))\n",
    "print(\"Total number of serial numbers missing - {}\".format(serial_numbers_missing))\n",
    "'''\n",
    "# print(df_orders.shape)\n",
    "df_orders = df_orders.append(df_new_rows, ignore_index=True) \n",
    "''' merging the new rows with the additional serial numbers to the main DF'''\n",
    "# print(df_orders.shape)\n",
    "print(\"Total rows after unpacking the Serial numbers - {}\".format(df_orders.shape[0]))\n",
    "### Order Tracking file dataframe prepared\n",
    "### Applying filters as per the request\n",
    "df_orders_filter_F = df_orders[(df_orders['Product Desc'] != \"CLIENT PERIPHERALS\") & (df_orders['Product Desc'] != \"SUPPORT SERVICES\")]  \n",
    "# print(df_orders_filter_F.shape)\n",
    "print(\"Removed {} rows for Product Description as CLIENT PERIPHERALS and SUPPORT SERVICES\".format(df_orders.shape[0] - df_orders_filter_F.shape[0]))\n",
    "df_orders_filter_G = df_orders_filter_F[(df_orders_filter_F['Brand Desc'] != \"PARTNER\") & (df_orders_filter_F['Brand Desc'] != \"UNKNOWN\" )]\n",
    "# print(df_orders_filter_G.shape)\n",
    "print(\"Removed {} rows for Brand Description as PARTNER and UNKNOWN\".format(df_orders_filter_F.shape[0] - df_orders_filter_G.shape[0]))\n",
    "df_orders_filtered = df_orders_filter_G\n",
    "print(\"Valid rows after applying filters - {}\".format(df_orders_filtered.shape[0]))\n",
    "### end of processing Order Tracking file\n",
    "# df_Output_File = pd.DataFrame()\n",
    "df_Output_File[\"Order Number\"] = df_orders_filtered[\"Order Num\"]\n",
    "df_Output_File[\"Serial Number\"] = df_orders_filtered[\"Combine svc tag\"]\n",
    "df_Output_File[\"PO Number\"] = df_orders_filtered[\"Po Num\"]\n",
    "df_Output_File[\"Order Qty\"] = df_orders_filtered[\"Order Qty\"]\n",
    "\n",
    "# df_Output_File\n",
    "df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP 2 #####\n",
    "\n",
    "df_daily_dashboard = pd.read_excel(dashboard_file, sheet_name=\"Page 1\", header=0, usecols=[\"Asset tag\", \"Serial number\", \"State\", \"Substate\", \"Assigned to\", \"Email\", \"Model\", \"Installed Date\", \"PO number\"], encoding=\"ISO-8859-1\", index_col=None, engine=None, na_values=None)\n",
    "\n",
    "# print(df_daily_dashboard)\n",
    "# print(df_daily_dashboard.shape[0])\n",
    "# cnt = 0\n",
    "serial_num_missing_from_dashboard = list()\n",
    "serial_num_match_with_dashboard = list()\n",
    "po_num_mismatch = list()\n",
    "po_num_matched = list()\n",
    "for row_idx_ in range(0, df_orders_filtered.shape[0]):  #looping the Order Tracking Report dataframe'''\n",
    "    serial_ordered = df_orders_filtered.iloc[row_idx_,4]  '''capture only the serial number'''\n",
    "#     print(serial_ordered)\n",
    "    serial_num_Flag = True ''' setting up a flag variable '''\n",
    "    counter = df_daily_dashboard.shape[0] - 1 '''setting a looping variable to the last row to check from the Dashboard DF'''\n",
    "    while (counter >= 0): '''looping back'''\n",
    "#         print(df_daily_dashboard.iloc[counter, 1])\n",
    "        if (df_daily_dashboard.iloc[counter, 1] == serial_ordered):\n",
    "            serial_num_Flag = True\n",
    "            serial_num_match_with_dashboard.append(row_idx_)\n",
    "            df_Output_File[]\n",
    "#             print(\"sr matched\")\n",
    "            break\n",
    "        else:\n",
    "            serial_num_Flag = False    \n",
    "        counter -= 1\n",
    "#     print(counter)\n",
    "    if (serial_num_Flag == False):\n",
    "        serial_num_missing_from_dashboard.append(row_idx_)\n",
    "    else:\n",
    "        if (df_daily_dashboard.iloc[counter, 8] != str(df_orders_filtered.iloc[row_idx_, 0])):\n",
    "            po_num_mismatch.append(counter)\n",
    "        else:\n",
    "            po_num_matched.append(counter)\n",
    "#     print(\"-\"*20)\n",
    "    \n",
    "print(len(serial_num_missing_from_dashboard))\n",
    "print(len(serial_num_match_with_dashboard))\n",
    "print(len(po_num_mismatch))\n",
    "print(len(po_num_matched))\n",
    "''' coping the required columns to the Output File DF '''\n",
    "df_Output_File[\"\"] = df_daily_dashboard[\"\"]\n",
    "\n",
    "# for po_ in po_num_mismatch:\n",
    "#     df_daily_dashboard.iloc[po_,8].style.applymap(color='darkorange')\n",
    "\n",
    "    df_daily_dashboard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### STEP 3 #####\n",
    "\n",
    "df_DXC_Lease_Supl_Cons= pd.read_excel(lease_supl_cons_file, sheet_name=\"Asset List\", encoding=\"ISO-8859-1\", index_col=None, engine=None, na_values=None)\n",
    "    ## removing the top blank rows\n",
    "df_DXC_Lease_Supl_Cons= df_DXC_Lease_Supl_Cons[9:]\n",
    "df_DXC_Lease_Supl_Cons= df_DXC_Lease_Supl_Cons.reset_index(drop = True)\n",
    "    ## resetting the start row\n",
    "df_DXC_Lease_Supl_Cons.columns = df_DXC_Lease_Supl_Cons.iloc[0]\n",
    "    ## resetting the start row of the data\n",
    "df_DXC_Lease_Supl_Cons= df_DXC_Lease_Supl_Cons[1:]\n",
    "    ## dropping all completely blank rows and retain the same dataframe\n",
    "df_DXC_Lease_Supl_Cons.dropna(how = 'all', inplace=True)\n",
    "    ## Unpacking the last column with merged cells accross column\n",
    "df_DXC_Lease_Supl_Cons[\"Lease Suppliment\"].fillna(method = 'ffill', inplace=True)\n",
    "    ## dropping more unnecessary rows having \"EQUIPMENT DESCRIPTION\"\n",
    "df_DXC_Lease_Supl_Cons.dropna(how = 'any', inplace=True)\n",
    "print(\"Total count of Invoice Number rows - {}\".format(df_DXC_Lease_Supl_Cons.shape[0]))\n",
    "# print(df_DXC_Lease_Supl_Cons.shape)\n",
    "# df_DXC_Lease_Supl_Cons.iloc[80:]\n",
    "\n",
    "    ### Iterating the dataframe for splitting the \"Tag Number\" column (Serial Number). \n",
    "    ### This column has seperator as 'space', 'new line', 'carriage return' and line endigs with 'new line'\n",
    "start_row = 0\n",
    "last_row = df_DXC_Lease_Supl_Cons.shape[0]\n",
    "tag_nums_each_row  = tag_num_total_count = 0\n",
    "df_new_rows = pd.DataFrame().reindex(columns=df_DXC_Lease_Supl_Cons.columns)\n",
    "# print(df_temp)\n",
    "# print(type(df_temp))\n",
    "# print(df_temp.shape)\n",
    "\n",
    "for rows_ in range(start_row, last_row):\n",
    "    tags = df_DXC_Lease_Supl_Cons.iloc[rows_,6]\n",
    "    tags_1 =  tags.replace(\"\\n\",\" \")  ## removing 'new line'\n",
    "    tags_2 = tags_1.replace(\"\\r\",\"\")  ## removing 'carriage return'\n",
    "    tag_list = tags_2.split(sep = \" \")  ## string to list -> delimiter = 'space'\n",
    "    tag_list = list(filter(None, tag_list)) ## removing empty list entries formed due to the previous processings\n",
    "#     print(tag_list, len(tag_list))\n",
    "#     print(\"-\"*30)\n",
    "    tag_nums_each_row = len(tag_list)  \n",
    "    tag_num_total_count = tag_num_total_count + tag_nums_each_row\n",
    "    \n",
    "#     print(\"{} more tag/serial numbers found. A total of {} tag/serial numbers tracked so far..\".format(tag_nums_each_row, tag_num_total_count))\n",
    "    if tag_nums_each_row > 1:\n",
    "        df_DXC_Lease_Supl_Cons.iloc[rows_,6] = tag_list[0]\n",
    "        tag_list_tail = tag_list[1:]\n",
    "        cnt = 0\n",
    "        for expand_rows_ in range(0, len(tag_list_tail)):\n",
    "            new_list = list()\n",
    "            new_list.append(df_DXC_Lease_Supl_Cons.iloc[rows_,0])\n",
    "            new_list.append(df_DXC_Lease_Supl_Cons.iloc[rows_,1])\n",
    "            new_list.append(df_DXC_Lease_Supl_Cons.iloc[rows_,2])\n",
    "            new_list.append(df_DXC_Lease_Supl_Cons.iloc[rows_,3])\n",
    "            new_list.append(df_DXC_Lease_Supl_Cons.iloc[rows_,4])\n",
    "            new_list.append(df_DXC_Lease_Supl_Cons.iloc[rows_,5])\n",
    "            new_list.append(tag_list_tail[expand_rows_])\n",
    "            new_list.append(df_DXC_Lease_Supl_Cons.iloc[rows_,7])\n",
    "            temp_series = pd.Series(new_list, name=\"MoreTags\", index = df_DXC_Lease_Supl_Cons.columns )\n",
    "            df_new_rows = df_new_rows.append(temp_series, ignore_index=True)\n",
    "            cnt += 1\n",
    "#         print(\"{} more new rows added ... \".format(cnt))\n",
    "#     print(\"{} total new rows added\".format(df_new_rows.shape[0]))\n",
    "print(\"A total of {} tag/serial numbers have been tracked.\".format(tag_num_total_count))\n",
    "df_DXC_Lease_Supl_Cons= df_DXC_Lease_Supl_Cons.append(df_new_rows, ignore_index=True)\n",
    "print(\"Post processing a total of {} new rows added\".format(df_new_rows.shape[0]))\n",
    "print(\"Final size of the Lease Supplement dataframe - {} rows...\".format(df_DXC_Lease_Supl_Cons.shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### STEP 4 #####\n",
    "\n",
    "df_monthly_rental_prize =  pd.read_excel(monthly_rental_file, sheet_name=\"Sheet1\", header=0, encoding=\"ISO-8859-1\", index_col=None, engine=None, na_values=None)\n",
    "print(df_monthly_rental_prize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}