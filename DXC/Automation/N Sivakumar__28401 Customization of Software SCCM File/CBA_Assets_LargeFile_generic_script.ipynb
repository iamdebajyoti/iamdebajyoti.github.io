{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "##### author: Debajyoti Dutta\n",
    "##### email: debajyoti.dutta@dxc.com\n",
    "##### last_update_date: 2020-12-10\n",
    "##### version: 2-dot-1\n",
    "##################################################\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### GLOBAL CONFIGURATIONS\n",
    "source_column_names = [\"Assettag\", \"Serial\", \"Systemname\", \"NetID\", \"Asset_Number\", \"Registry\", \"Number_2\", \"SoftwareTitle\", \"SoftwareVersion\", \"ScanDate\", \"OSVersion\", \"OSEdition\", \"Number_3\"]\n",
    "dump_source_location =\"\"\n",
    "report_store_name=\"\"\n",
    "### ALL FUNCTION DEFINITIONS\n",
    "##############################################################################################################################\n",
    "##### ##### START DEFINITION OF -- setting_locations()\n",
    "def setting_locations():\n",
    "    global dump_source_location\n",
    "    dump_source_location=input(r'Please mention the full path of report dump source folder :: ')  \n",
    "    #dump_source_location =r\"C:\\DEB_CloudData\\CBA_BAM\"\n",
    "    global report_store_name\n",
    "    report_store_name = \"Custom_Reports_\"\n",
    "    if os.path.exists(os.path.join(dump_source_location, report_store_name)) \\\n",
    "                      and not os.path.isfile(os.path.join(dump_source_location, report_store_name)):\n",
    "#         print(\" .. Custom Reports store exists ...\\n\")\n",
    "        os.chdir(os.path.join(dump_source_location, report_store_name))\n",
    "    else:\n",
    "        os.mkdir(report_store_name)\n",
    "#         print(\" Custom Reports store created\\n\")\n",
    "#         print(\"-\"*30)\n",
    "#         os.chdir(os.path.join(dump_source_location, report_store_name))\n",
    "\n",
    "    return dump_source_location\n",
    "##### ##### ##### END DEFINITION OF -- setting_locations()\n",
    "##############################################################################################################################\n",
    "##### ##### START DEFINITION OF -- source_report_selection()\n",
    "def source_report_selection(dump_source_location_):\n",
    "    dump_source_folder = os.listdir(dump_source_location_)\n",
    "    all_files_dict = {} ## define the dictionary for the folder contents\n",
    "    selected_files_list = [] ## define the list to capture the files chosen by user\n",
    "    decision=\"\" ## looping variable for raw data source file selection\n",
    "    while decision != 'x':\n",
    "        print(\"SELECT THE RAW DATA FILES ...\\n (CHOOSE THE CORRESPONDING FILE NUMBER/S) \\n\\t ( for MULTIPLE FILES please use Comma \\\",\\\" in between ) \\n TO Select All press - A/a \\n TO EXIT press - X/x)\" )\n",
    "        print(\"-\"*40)      \n",
    "        i = 1\n",
    "        for file_ in dump_source_folder: ## capture the folder contents as a dictionary                                                                                             #\n",
    "            all_files_dict[i] = file_\n",
    "            i +=1 \n",
    "        pprint(all_files_dict) ## showing the file list to the user to choose the raw data file to scan\n",
    "        print(\"-\"*30)\n",
    "    #     selected_files=input(': ')\n",
    "    #     Selected_Files_=selected_files.split(sep= \",\")\n",
    "        Selected_Files_=input('::  ').split(sep= \",\")## capturing the user's choice - input string >> split to >> list \n",
    "        if Selected_Files_[0] == \"a\" or Selected_Files_[0] == \"A\":\n",
    "            count = 1\n",
    "            for i in dump_source_folder:\n",
    "                print(\"{}. {}\".format(count, i))\n",
    "                selected_files_list.append(i)\n",
    "                count += 1\n",
    "        elif Selected_Files_[0] == \"x\" or Selected_Files_[0] == \"X\":\n",
    "            return\n",
    "        else:\n",
    "            print(\"\\nYou have selected the following reports : \", end = \"\")\n",
    "    #     print(Selected_Files_) ## shows the chosen file numbers to user\n",
    "            print(\"\\n\")\n",
    "            for i in Selected_Files_:\n",
    "                if i != \" \" and i != '':\n",
    "                    print(\"\\t\", end = \"\")\n",
    "                    print(i, end = \" : \",)\n",
    "                    i_=int(i)\n",
    "                    print(all_files_dict[i_]) ## display the values picked from the dict\n",
    "                    selected_files_list.append(all_files_dict[i_]) ## populate the list from the data picked from the dict\n",
    "        print(\"\\nProceed to Scan the reports by  (Y/y) or \\n\\t Change report selection by  (N/n) OR \\n\\t Exit the script by  X/x \")\n",
    "        ## capture user's decision and proceed accordingly\n",
    "        decision=input(r'::  ').lower()  \n",
    "        if decision == 'y':\n",
    "#             print(Selected_Files_, selected_files_list)\n",
    "            return selected_files_list\n",
    "        elif decision == 'n':\n",
    "            os.system('CLS')\n",
    "            print(\"-\"*30)\n",
    "            print(\"-\"*10, end =\" \")\n",
    "            print(\".. please select AGAIN ...\\n\")\n",
    "            selected_files_list.clear()\n",
    "        elif decision == 'x':\n",
    "            print(\"Exiting\")\n",
    "            sys.exit(\"Exiting\")\n",
    "            selected_files_list.clear()\n",
    "        else:\n",
    "            print(\"Please select appropriately\\n\")\n",
    "            selected_files_list.clear()\n",
    "##### ##### ##### END DEFINITION OF -- source_report_selection()\n",
    "##############################################################################################################################\n",
    "##### ##### START DEFINITION OF -- dump_data_scanning()\n",
    "def dump_data_scanning(selected_source_reports_, dump_source_location_, source_column_names_):\n",
    "    os.chdir(dump_source_location_)\n",
    "    collated_df = pd.DataFrame()\n",
    "    print(\"-\"*60)\n",
    "    print(\"\\n...Raw Data scan started..\\n\")\n",
    "    for file_ in selected_source_reports_:\n",
    "        print(file_, end = \" ...processing... \")\n",
    "        temp_df = pd.DataFrame()\n",
    "        with open(file_) as csvfile_:\n",
    "            dialect=csv.Sniffer().sniff(csvfile_.read(14734))\n",
    "        csv_in_chunks=pd.read_csv(file_, header=None, iterator=True, chunksize=100000, sep=\",\", quotechar='\"', names=source_column_names_, encoding=\"ISO-8859-1\", index_col=None, engine='python', error_bad_lines=False, dialect=dialect)\n",
    "        temp_df=pd.concat(csv_in_chunks, ignore_index=True)\n",
    "        ## concating all rows in the dataframe \n",
    "        rows_, cols_ = temp_df.shape\n",
    "        print(\" File has {} rows and {} columns.. PLEASE HOLD ...\".format(rows_, cols_))\n",
    "        temp_df[\"Filename\"]=file_\n",
    "#         print(temp_df.shape)\n",
    "        collated_df=pd.concat([collated_df, temp_df], ignore_index=True)\n",
    "        ## collating all the dataframes\n",
    "    print(\"\\n...Raw Data scan completed..\\n\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"--- GENERATING PIVOTED SUMMARY FOR COLUMN 'SoftwareTitle' ----- please hold -----\")\n",
    "    os.chdir(os.path.join(dump_source_location, report_store_name))\n",
    "#     collated_df.columns = collated_df.columns.get_level_values(0)\n",
    "    collated_df_pivoted1 = pd.pivot_table(collated_df, values='Systemname', index=['SoftwareTitle'], columns=['OSVersion'], aggfunc=pd.Series.count, margins=True)\n",
    "    collated_df_pivoted2 = pd.pivot_table(collated_df, values='Systemname', index=['SoftwareTitle','OSVersion'], aggfunc=pd.Series.count, margins=True)\n",
    "    collated_df_grouped = collated_df.groupby(by=[\"SoftwareTitle\",\"OSVersion\"]).count()\n",
    "#     collated_df_pivoted = pd.pivot_table(collated_df, values='Systemname', index=['SoftwareTitle'], columns=['OSVersion'], aggfunc='count') # old style count\n",
    "#     print(collated_df.index, collated_df.columns, collated_df_pivoted, collated_df_grouped[\"Assettag\"])\n",
    "    file_ = \"Pivot_Result_\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") + \".xlsx\"\n",
    "#     print(file_)\n",
    "    with pd.ExcelWriter(file_) as writer:\n",
    "        collated_df_pivoted1.to_excel(writer, sheet_name=\"Pivot_Type_1\", engine='xlsxwriter', header=True)\n",
    "        collated_df_pivoted2.to_excel(writer, sheet_name=\"Pivot_Type_2\", engine='xlsxwriter', header=True)\n",
    "        collated_df_grouped.to_excel(writer, sheet_name=\"GroupBy_Result\", engine='xlsxwriter', header=True)\n",
    "        print(\"\\nSAVED TO FILE...  \"+ file_ + \"  in  \" + os.getcwd()+\"\\n\")\n",
    "    writer.save()\n",
    "    print(\"-\"*40)\n",
    "    return collated_df\n",
    "##### ##### ##### END DEFINITION OF -- dump_data_scanning()\n",
    "##############################################################################################################################\n",
    "##### ##### START DEFINITION OF -- apply_filter()\n",
    "def apply_filter(collated_df_, source_column_names_):\n",
    "    print(\"\\nPlease select the column number of the filter/s you want to use \\n\\t ( for MULTIPLE FILTERS please use Comma \\\",\\\" in between ) \\n The script will apply the filters in the sequence you mention here ..\")\n",
    "    print(\"\\n\\nThe avaiable report filters are .. \\n\")\n",
    "    print(\"-\"*20)\n",
    "    count=1\n",
    "    for i in source_column_names_:\n",
    "        print(\"{}. {}\".format(count, i))\n",
    "        count += 1\n",
    "    print(\"-\"*20)\n",
    "    Selected_filters=input(r'Enter filter number/s ::  ').split(sep=\",\") ## choosing the column headers to be used for filtering\n",
    "    print(\"-\"*20)\n",
    "    chosen_columns = []\n",
    "    keywords = []\n",
    "    sp_chars = string.punctuation\n",
    "    for i in Selected_filters:\n",
    "        if i != \" \" and i != '':\n",
    "            i_=(int(i)- 1)\n",
    "            print(\"\\nPlease specify the search keyword for column -- \\\"{}\\\" \\n ( SPECIAL CHARACTERS  ONLY DOT(.) AND SPACE  ARE ALLOWED)\\n\".format(source_column_names_[i_]))\n",
    "            ## checking for special characters\n",
    "            SPChar_check = True\n",
    "            while SPChar_check != False:\n",
    "                keyword=input(r'::  ')\n",
    "                keyword_split = [keyword[i:i+1] for i in range(0, len(keyword), 1)]\n",
    "                bool_List_For_SP_chars = list(map(lambda char: char in sp_chars, keyword_split))\n",
    "                SPChar_check = False\n",
    "                for (input_chars, bool_idx) in zip(keyword_split, bool_List_For_SP_chars):\n",
    "                    if bool_idx == True and input_chars != \".\":\n",
    "                        print(\"unaccepted character - \\\"{}\\\" used in the search keyword \".format(input_chars))\n",
    "                        SPChar_check = True\n",
    "                if SPChar_check == True:\n",
    "                    print(\"Please try again ...\")\n",
    "            chosen_columns.append(source_column_names_[i_])\n",
    "            keywords.append(keyword)\n",
    "#     print(chosen_columns)\n",
    "#     print(keywords)\n",
    "    filtered_df = collated_df\n",
    "    for (col,kw) in zip(chosen_columns, keywords):\n",
    "#         print(i,j)\n",
    "#         filtered_df = filtered_df[filtered_df[col].str.contains(kw, case=False, na=False) ==True]\n",
    "        filtered_df = filtered_df[filtered_df[col].str.contains(pat = kw, case=False, na=False,regex=True) ==True]\n",
    "#         filtered_df = filtered_df[filtered_df[col].str.extractall(kw) ==True]\n",
    "    print(\"...s e a r c h i n g  f o r  ......\", end =\"  \")\n",
    "    print(keywords)\n",
    "#     print(filtered_df.shape)\n",
    "    if filtered_df.shape[0] == 0:\n",
    "        print(\"\\nNo matching records found... \")\n",
    "    else:\n",
    "        print(\"\\nSearch returned {} records in...\".format(filtered_df.shape[0]))\n",
    "        filtered_df_grouped=filtered_df.groupby(by=[\"Filename\"]).count()\n",
    "        print(filtered_df_grouped[\"Systemname\"])\n",
    "        print(\"-\"*20)\n",
    "    next_step = \"\"\n",
    "    while next_step != 'x':\n",
    "        print(\"\\nView seacrh results sample on screen (W/w) \\\n",
    "          \\nGenerate the search report as Excel file (R/r) \\\n",
    "          \\nTry a new Search (N/n) \\\n",
    "          \\nExit the script (X/x)\")\n",
    "        next_step=input(r'::  ').lower()\n",
    "        if next_step == 'w':\n",
    "            print(filtered_df.head())\n",
    "            print(\"-\"*40)\n",
    "            carry_on_= input(r'Save this search result in a file (V/v) OR Skip (K/k) ::  ').lower()\n",
    "            if carry_on_ == 'v':\n",
    "                save_search_to_excel(filtered_df, chosen_columns, keywords)\n",
    "            elif carry_on_ == 'k':\n",
    "                break\n",
    "            else:\n",
    "                print(\"\\nPlease select appropriately\\n\")\n",
    "        elif next_step == 'n':\n",
    "            print(\"-\"*30)\n",
    "            print(\"-\"*30)\n",
    "            apply_filter(collated_df, source_column_names)\n",
    "        elif next_step == 'r':\n",
    "            save_search_to_excel(filtered_df, chosen_columns, keywords)\n",
    "            print(\"-\"*40)\n",
    "            carry_on_= input(r'Start a new Search (S/s) OR Exit (X/x) ::  ').lower()\n",
    "            if carry_on_ == 's':\n",
    "                apply_filter(collated_df, source_column_names)\n",
    "            elif carry_on_ == 'x':\n",
    "                print(\"Exiting\")\n",
    "                sys.exit(\"Exiting\")\n",
    "            else:\n",
    "                print(\"\\nPlease select appropriately\\n\")\n",
    "        elif next_step == 'x':\n",
    "            print(\"Exiting\")\n",
    "            sys.exit(\"Exiting\")\n",
    "        else:\n",
    "            print(\"\\nPlease select appropriately\\n\")\n",
    "##### ##### ##### END DEFINITION OF -- apply_filter()\n",
    "##############################################################################################################################\n",
    "##### ##### START DEFINITION OF -- save_search_to_excel()\n",
    "def save_search_to_excel(filtered_df_, chosen_columns_, keywords_):\n",
    "# def save_report_to_excel():\n",
    "    global report_store_name\n",
    "    print(\"-\"*40)\n",
    "    os.chdir(dump_source_location)\n",
    "    os.chdir(report_store_name)  \n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    report_folder_name = timestamp\n",
    "    os.mkdir(report_folder_name)\n",
    "    os.chdir(os.path.join(dump_source_location, report_store_name, report_folder_name))\n",
    "    ## excel filename creation\n",
    "    name_ = \"\"\n",
    "    for i in keywords_: ## for single or multi keyword cases\n",
    "        name_ += i + \"-\" \n",
    "    name_=\"Results-for__\"+name_+\".xlsx\" \n",
    "    ## actual excel writing begins here\n",
    "    total_rows, total_columns = filtered_df_.shape\n",
    "    max_excelrows_per_worksheet = (1048576 - 1) ## total number of  rows allowed per worksheet minus 1 for header row\n",
    "    start_pos = 0 ## represents first row of the data frame\n",
    "    end_pos = (max_excelrows_per_worksheet - 1) ## since the start row of dataframe has index 0 instead of index 1\n",
    "    sheet_count=0\n",
    "    if total_rows > max_excelrows_per_worksheet: ## case for multisheet writing ... a single excel worksheet supports only 10,48,576 rows.. skipping the first row for column header\n",
    "        print(\"... WRITING EXCEL FILE - PLEASE HOLD ...\")\n",
    "        with pd.ExcelWriter(name_) as writer:\n",
    "            while True :\n",
    "#                 print(\"start_pos {}, end_pos {}\".format(start_pos, end_pos))\n",
    "                if end_pos < total_rows :\n",
    "                    df_chunk = filtered_df_.iloc[start_pos:end_pos,:]\n",
    "                    sheet_count += 1    \n",
    "                    df_chunk.to_excel(writer, sheet_name=f'Sheet {sheet_count}', engine='xlsxwriter', header=True, index=False)\n",
    "                    writer.save()\n",
    "                    print(\"Added UPTO {}th record from search results in Sheet num {}\".format(end_pos+1,sheet_count))\n",
    "                    start_pos = (end_pos + 1)\n",
    "                    end_pos = (end_pos + max_excelrows_per_worksheet)          \n",
    "                else:\n",
    "                    df_chunk = filtered_df_.iloc[start_pos:,:]\n",
    "                    sheet_count += 1\n",
    "                    df_chunk.to_excel(writer, sheet_name=f'Sheet {sheet_count}', engine='xlsxwriter', header=True, index=False)\n",
    "                    writer.save()\n",
    "                    print(\"Added the LAST {} records from search results in Sheet num {}\".format(total_rows-start_pos,sheet_count))\n",
    "                    break\n",
    "    else:\n",
    "        print(\"... WRITING EXCEL FILE - PLEASE HOLD ...\", end=\" \") ## case for single sheet writing - total_rows <= max_excelrows_per_worksheet\n",
    "        with pd.ExcelWriter(name_) as writer:\n",
    "            sheet_count += 1 \n",
    "            filtered_df_.to_excel(writer, sheet_name=f'Sheet {sheet_count}', engine='xlsxwriter', header=True, index=False)\n",
    "            print(\"Added {} records from search results in Sheet num {}\".format(total_rows,sheet_count))\n",
    "            writer.save()\n",
    "    print(\"\\n\\nReport saved in file \\\"{}\\\" \".format(name_))\n",
    "    print(\"\\nTo access the above report please visit >> {}\\n\".format(os.getcwd()))\n",
    "##### ##### ##### END DEFINITION OF -- save_search_to_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "##### os.system('CLS')\n",
    "print(\"-\"*60)\n",
    "print(\"-\"*20, end=\" \")\n",
    "print(\"Step 0 - SETTING LOCATIONS\")\n",
    "print(\"-\"*60)\n",
    "setting_locations()\n",
    "# print(dump_source_location)\n",
    "########################################################################################################################\n",
    "os.system('CLS')\n",
    "print(\"-\"*60)\n",
    "print(\"-\"*20, end=\" \")\n",
    "print(\"Step 1 - SELECTING THE DUMP DATA\")\n",
    "print(\"-\"*60)\n",
    "os.chdir(dump_source_location)\n",
    "selected_source_reports = source_report_selection(dump_source_location)\n",
    "########################################################################################################################\n",
    "os.system('CLS')\n",
    "if selected_source_reports == None:\n",
    "    print(\"Exiting\")\n",
    "    sys.exit(\"Exiting\")\n",
    "print(\"-\"*60)\n",
    "print(\"-\"*20, end=\" \")\n",
    "print(\"Step 2 - DATA PROCESSING AND SUMMARY\")\n",
    "print(\"-\"*60)\n",
    "collated_df=dump_data_scanning(selected_source_reports, dump_source_location, source_column_names)\n",
    "########################################################################################################################\n",
    "if input(r'-- P R E S S  X/x TO EXIT     O R  A N Y  O T H E R  K E Y  T O  C O N T I N U E  -- ').lower() == \"x\":\n",
    "    sys.exit(\"Exiting\")\n",
    "os.system('CLS')\n",
    "if collated_df.empty :\n",
    "    print(\"Exiting\")\n",
    "    sys.exit(\"Exiting\")\n",
    "print(\"-\"*60)\n",
    "print(\"-\"*20, end=\" \")\n",
    "print(\"Step 3 - DATA FILT7ERING AND CUSTOM REPORTS\")\n",
    "print(\"-\"*60)\n",
    "apply_filter(collated_df, source_column_names)\n",
    "########################################################################################################################\n",
    "#######################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
